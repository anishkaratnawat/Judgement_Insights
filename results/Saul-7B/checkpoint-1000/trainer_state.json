{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.13478905512872355,
  "eval_steps": 500,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 0.32466745376586914,
      "learning_rate": 5.6053811659192826e-05,
      "loss": 1.844,
      "step": 25
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.347718596458435,
      "learning_rate": 0.00011210762331838565,
      "loss": 1.7502,
      "step": 50
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.40168729424476624,
      "learning_rate": 0.00016816143497757848,
      "loss": 1.6423,
      "step": 75
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9718135595321655,
      "learning_rate": 0.0002242152466367713,
      "loss": 1.5704,
      "step": 100
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.2708575427532196,
      "learning_rate": 0.0002802690582959641,
      "loss": 1.56,
      "step": 125
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.6746169328689575,
      "learning_rate": 0.00033632286995515697,
      "loss": 1.5388,
      "step": 150
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.2609868049621582,
      "learning_rate": 0.0003923766816143498,
      "loss": 1.558,
      "step": 175
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6734411120414734,
      "learning_rate": 0.0004484304932735426,
      "loss": 1.5076,
      "step": 200
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.29141339659690857,
      "learning_rate": 0.0005044843049327355,
      "loss": 1.5284,
      "step": 225
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5601041913032532,
      "learning_rate": 0.0005605381165919282,
      "loss": 1.5105,
      "step": 250
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.2770930528640747,
      "learning_rate": 0.0006165919282511211,
      "loss": 1.4898,
      "step": 275
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.6870507597923279,
      "learning_rate": 0.0006726457399103139,
      "loss": 1.5312,
      "step": 300
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.2940453588962555,
      "learning_rate": 0.0007286995515695067,
      "loss": 1.5031,
      "step": 325
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.542370080947876,
      "learning_rate": 0.0007847533632286996,
      "loss": 1.5199,
      "step": 350
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.34602776169776917,
      "learning_rate": 0.0008408071748878924,
      "loss": 1.4807,
      "step": 375
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7983356714248657,
      "learning_rate": 0.0008968609865470852,
      "loss": 1.5126,
      "step": 400
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.34746670722961426,
      "learning_rate": 0.000952914798206278,
      "loss": 1.5623,
      "step": 425
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.989680290222168,
      "learning_rate": 0.0009999998094024085,
      "loss": 1.5459,
      "step": 450
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.31377050280570984,
      "learning_rate": 0.000999989981746913,
      "loss": 1.5139,
      "step": 475
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6926711201667786,
      "learning_rate": 0.0009999652639889381,
      "loss": 1.5138,
      "step": 500
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3471492528915405,
      "learning_rate": 0.000999925656864598,
      "loss": 1.5744,
      "step": 525
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8570772409439087,
      "learning_rate": 0.0009998711615534243,
      "loss": 1.5303,
      "step": 550
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3814949691295624,
      "learning_rate": 0.0009998017796783315,
      "loss": 1.5409,
      "step": 575
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.6623942255973816,
      "learning_rate": 0.0009997175133055675,
      "loss": 1.5337,
      "step": 600
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.37516075372695923,
      "learning_rate": 0.0009996183649446523,
      "loss": 1.4996,
      "step": 625
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6325153112411499,
      "learning_rate": 0.0009995043375483033,
      "loss": 1.505,
      "step": 650
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.36859995126724243,
      "learning_rate": 0.0009993754345123482,
      "loss": 1.4939,
      "step": 675
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8028324246406555,
      "learning_rate": 0.0009992316596756227,
      "loss": 1.5119,
      "step": 700
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.37224170565605164,
      "learning_rate": 0.0009990730173198563,
      "loss": 1.5225,
      "step": 725
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.0388263463974,
      "learning_rate": 0.000998899512169546,
      "loss": 1.4944,
      "step": 750
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.41761526465415955,
      "learning_rate": 0.0009987111493918142,
      "loss": 1.5525,
      "step": 775
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.8520150780677795,
      "learning_rate": 0.000998507934596255,
      "loss": 1.5659,
      "step": 800
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.38275524973869324,
      "learning_rate": 0.0009982898738347685,
      "loss": 1.5131,
      "step": 825
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.0187994241714478,
      "learning_rate": 0.0009980569736013788,
      "loss": 1.506,
      "step": 850
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4613713324069977,
      "learning_rate": 0.0009978092408320413,
      "loss": 1.5288,
      "step": 875
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.972176730632782,
      "learning_rate": 0.0009975466829044365,
      "loss": 1.4996,
      "step": 900
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4071440100669861,
      "learning_rate": 0.0009972693076377502,
      "loss": 1.5245,
      "step": 925
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.8675865530967712,
      "learning_rate": 0.0009969771232924403,
      "loss": 1.5258,
      "step": 950
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3933359980583191,
      "learning_rate": 0.0009966701385699904,
      "loss": 1.5671,
      "step": 975
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.7701619267463684,
      "learning_rate": 0.000996348362612652,
      "loss": 1.4913,
      "step": 1000
    }
  ],
  "logging_steps": 25,
  "max_steps": 14838,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 1000,
  "total_flos": 2.043665892667392e+17,
  "train_batch_size": 5,
  "trial_name": null,
  "trial_params": null
}
