{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.8087343307723412,
  "eval_steps": 500,
  "global_step": 6000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 0.32466745376586914,
      "learning_rate": 5.6053811659192826e-05,
      "loss": 1.844,
      "step": 25
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.347718596458435,
      "learning_rate": 0.00011210762331838565,
      "loss": 1.7502,
      "step": 50
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.40168729424476624,
      "learning_rate": 0.00016816143497757848,
      "loss": 1.6423,
      "step": 75
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9718135595321655,
      "learning_rate": 0.0002242152466367713,
      "loss": 1.5704,
      "step": 100
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.2708575427532196,
      "learning_rate": 0.0002802690582959641,
      "loss": 1.56,
      "step": 125
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.6746169328689575,
      "learning_rate": 0.00033632286995515697,
      "loss": 1.5388,
      "step": 150
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.2609868049621582,
      "learning_rate": 0.0003923766816143498,
      "loss": 1.558,
      "step": 175
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6734411120414734,
      "learning_rate": 0.0004484304932735426,
      "loss": 1.5076,
      "step": 200
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.29141339659690857,
      "learning_rate": 0.0005044843049327355,
      "loss": 1.5284,
      "step": 225
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5601041913032532,
      "learning_rate": 0.0005605381165919282,
      "loss": 1.5105,
      "step": 250
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.2770930528640747,
      "learning_rate": 0.0006165919282511211,
      "loss": 1.4898,
      "step": 275
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.6870507597923279,
      "learning_rate": 0.0006726457399103139,
      "loss": 1.5312,
      "step": 300
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.2940453588962555,
      "learning_rate": 0.0007286995515695067,
      "loss": 1.5031,
      "step": 325
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.542370080947876,
      "learning_rate": 0.0007847533632286996,
      "loss": 1.5199,
      "step": 350
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.34602776169776917,
      "learning_rate": 0.0008408071748878924,
      "loss": 1.4807,
      "step": 375
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7983356714248657,
      "learning_rate": 0.0008968609865470852,
      "loss": 1.5126,
      "step": 400
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.34746670722961426,
      "learning_rate": 0.000952914798206278,
      "loss": 1.5623,
      "step": 425
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.989680290222168,
      "learning_rate": 0.0009999998094024085,
      "loss": 1.5459,
      "step": 450
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.31377050280570984,
      "learning_rate": 0.000999989981746913,
      "loss": 1.5139,
      "step": 475
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6926711201667786,
      "learning_rate": 0.0009999652639889381,
      "loss": 1.5138,
      "step": 500
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3471492528915405,
      "learning_rate": 0.000999925656864598,
      "loss": 1.5744,
      "step": 525
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8570772409439087,
      "learning_rate": 0.0009998711615534243,
      "loss": 1.5303,
      "step": 550
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3814949691295624,
      "learning_rate": 0.0009998017796783315,
      "loss": 1.5409,
      "step": 575
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.6623942255973816,
      "learning_rate": 0.0009997175133055675,
      "loss": 1.5337,
      "step": 600
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.37516075372695923,
      "learning_rate": 0.0009996183649446523,
      "loss": 1.4996,
      "step": 625
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6325153112411499,
      "learning_rate": 0.0009995043375483033,
      "loss": 1.505,
      "step": 650
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.36859995126724243,
      "learning_rate": 0.0009993754345123482,
      "loss": 1.4939,
      "step": 675
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8028324246406555,
      "learning_rate": 0.0009992316596756227,
      "loss": 1.5119,
      "step": 700
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.37224170565605164,
      "learning_rate": 0.0009990730173198563,
      "loss": 1.5225,
      "step": 725
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.0388263463974,
      "learning_rate": 0.000998899512169546,
      "loss": 1.4944,
      "step": 750
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.41761526465415955,
      "learning_rate": 0.0009987111493918142,
      "loss": 1.5525,
      "step": 775
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.8520150780677795,
      "learning_rate": 0.000998507934596255,
      "loss": 1.5659,
      "step": 800
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.38275524973869324,
      "learning_rate": 0.0009982898738347685,
      "loss": 1.5131,
      "step": 825
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.0187994241714478,
      "learning_rate": 0.0009980569736013788,
      "loss": 1.506,
      "step": 850
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4613713324069977,
      "learning_rate": 0.0009978092408320413,
      "loss": 1.5288,
      "step": 875
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.972176730632782,
      "learning_rate": 0.0009975466829044365,
      "loss": 1.4996,
      "step": 900
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4071440100669861,
      "learning_rate": 0.0009972693076377502,
      "loss": 1.5245,
      "step": 925
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.8675865530967712,
      "learning_rate": 0.0009969771232924403,
      "loss": 1.5258,
      "step": 950
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3933359980583191,
      "learning_rate": 0.0009966701385699904,
      "loss": 1.5671,
      "step": 975
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.7701619267463684,
      "learning_rate": 0.000996348362612652,
      "loss": 1.4913,
      "step": 1000
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.41116154193878174,
      "learning_rate": 0.000996011805003171,
      "loss": 1.5485,
      "step": 1025
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.7346125841140747,
      "learning_rate": 0.0009956604757645027,
      "loss": 1.5368,
      "step": 1050
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4338909387588501,
      "learning_rate": 0.0009952943853595135,
      "loss": 1.5037,
      "step": 1075
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.0304358005523682,
      "learning_rate": 0.0009949135446906691,
      "loss": 1.5516,
      "step": 1100
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3904549479484558,
      "learning_rate": 0.0009945179650997103,
      "loss": 1.5534,
      "step": 1125
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.8949064016342163,
      "learning_rate": 0.000994107658367314,
      "loss": 1.532,
      "step": 1150
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.40997326374053955,
      "learning_rate": 0.0009936826367127438,
      "loss": 1.5532,
      "step": 1175
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.0326120853424072,
      "learning_rate": 0.0009932429127934852,
      "loss": 1.5353,
      "step": 1200
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4106033742427826,
      "learning_rate": 0.0009927884997048692,
      "loss": 1.5271,
      "step": 1225
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7355422377586365,
      "learning_rate": 0.0009923194109796815,
      "loss": 1.5271,
      "step": 1250
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.44236990809440613,
      "learning_rate": 0.0009918356605877609,
      "loss": 1.4871,
      "step": 1275
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.9521761536598206,
      "learning_rate": 0.0009913372629355814,
      "loss": 1.4818,
      "step": 1300
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.46171343326568604,
      "learning_rate": 0.0009908242328658249,
      "loss": 1.5406,
      "step": 1325
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.746675431728363,
      "learning_rate": 0.0009902965856569382,
      "loss": 1.5236,
      "step": 1350
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.417439728975296,
      "learning_rate": 0.000989754337022678,
      "loss": 1.5469,
      "step": 1375
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.9241145253181458,
      "learning_rate": 0.0009891975031116433,
      "loss": 1.5297,
      "step": 1400
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.4531482458114624,
      "learning_rate": 0.0009886261005067948,
      "loss": 1.5374,
      "step": 1425
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.9997047781944275,
      "learning_rate": 0.0009880401462249596,
      "loss": 1.5211,
      "step": 1450
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.459329754114151,
      "learning_rate": 0.000987439657716326,
      "loss": 1.5041,
      "step": 1475
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.8838251233100891,
      "learning_rate": 0.0009868246528639236,
      "loss": 1.5113,
      "step": 1500
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4548807144165039,
      "learning_rate": 0.0009861951499830894,
      "loss": 1.5186,
      "step": 1525
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.0964994430541992,
      "learning_rate": 0.0009855511678209243,
      "loss": 1.5251,
      "step": 1550
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4728405475616455,
      "learning_rate": 0.0009848927255557331,
      "loss": 1.5306,
      "step": 1575
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.9868845343589783,
      "learning_rate": 0.0009842198427964545,
      "loss": 1.4891,
      "step": 1600
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.45390117168426514,
      "learning_rate": 0.0009835325395820761,
      "loss": 1.5479,
      "step": 1625
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.0145013332366943,
      "learning_rate": 0.0009828308363810392,
      "loss": 1.5352,
      "step": 1650
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.43639957904815674,
      "learning_rate": 0.0009821147540906273,
      "loss": 1.5641,
      "step": 1675
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.9881660342216492,
      "learning_rate": 0.0009813843140363447,
      "loss": 1.5142,
      "step": 1700
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.3978832960128784,
      "learning_rate": 0.0009806395379712825,
      "loss": 1.5158,
      "step": 1725
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.1177687644958496,
      "learning_rate": 0.0009798804480754687,
      "loss": 1.4501,
      "step": 1750
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.48748499155044556,
      "learning_rate": 0.0009791070669552086,
      "loss": 1.5225,
      "step": 1775
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.0997127294540405,
      "learning_rate": 0.0009783194176424125,
      "loss": 1.5088,
      "step": 1800
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.4628203809261322,
      "learning_rate": 0.0009775175235939078,
      "loss": 1.4793,
      "step": 1825
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.754141628742218,
      "learning_rate": 0.0009767014086907427,
      "loss": 1.5198,
      "step": 1850
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.42553696036338806,
      "learning_rate": 0.0009758710972374729,
      "loss": 1.5109,
      "step": 1875
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.8072162866592407,
      "learning_rate": 0.0009750266139614391,
      "loss": 1.4948,
      "step": 1900
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.435613214969635,
      "learning_rate": 0.0009741679840120303,
      "loss": 1.4894,
      "step": 1925
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.923243522644043,
      "learning_rate": 0.000973295232959935,
      "loss": 1.4765,
      "step": 1950
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.411964476108551,
      "learning_rate": 0.0009724083867963787,
      "loss": 1.5235,
      "step": 1975
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.8363409042358398,
      "learning_rate": 0.0009715074719323514,
      "loss": 1.4897,
      "step": 2000
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.48569735884666443,
      "learning_rate": 0.00097059251519782,
      "loss": 1.5275,
      "step": 2025
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.9587534666061401,
      "learning_rate": 0.0009696635438409294,
      "loss": 1.5116,
      "step": 2050
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.42877620458602905,
      "learning_rate": 0.0009687205855271915,
      "loss": 1.4995,
      "step": 2075
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.969298779964447,
      "learning_rate": 0.0009677636683386606,
      "loss": 1.4857,
      "step": 2100
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.42877230048179626,
      "learning_rate": 0.0009667928207730978,
      "loss": 1.4703,
      "step": 2125
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.9090496897697449,
      "learning_rate": 0.0009658080717431222,
      "loss": 1.5401,
      "step": 2150
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.5189677476882935,
      "learning_rate": 0.0009648094505753486,
      "loss": 1.5519,
      "step": 2175
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.7682148814201355,
      "learning_rate": 0.0009637969870095167,
      "loss": 1.5036,
      "step": 2200
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.48559993505477905,
      "learning_rate": 0.0009627707111976027,
      "loss": 1.5076,
      "step": 2225
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.023287057876587,
      "learning_rate": 0.0009617306537029233,
      "loss": 1.512,
      "step": 2250
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.476704478263855,
      "learning_rate": 0.0009606768454992243,
      "loss": 1.4841,
      "step": 2275
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.0840306282043457,
      "learning_rate": 0.0009596093179697588,
      "loss": 1.4983,
      "step": 2300
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.46370431780815125,
      "learning_rate": 0.0009585281029063522,
      "loss": 1.5157,
      "step": 2325
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.9496181011199951,
      "learning_rate": 0.0009574332325084562,
      "loss": 1.4621,
      "step": 2350
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.46786776185035706,
      "learning_rate": 0.000956324739382189,
      "loss": 1.5208,
      "step": 2375
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.428635597229004,
      "learning_rate": 0.0009552026565393644,
      "loss": 1.48,
      "step": 2400
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.4893878102302551,
      "learning_rate": 0.0009540670173965089,
      "loss": 1.5486,
      "step": 2425
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.9355987310409546,
      "learning_rate": 0.0009529178557738667,
      "loss": 1.489,
      "step": 2450
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.42199021577835083,
      "learning_rate": 0.0009517552058943921,
      "loss": 1.4709,
      "step": 2475
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.9282339215278625,
      "learning_rate": 0.0009505791023827308,
      "loss": 1.5196,
      "step": 2500
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.462709903717041,
      "learning_rate": 0.0009493895802641879,
      "loss": 1.5444,
      "step": 2525
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.3179067373275757,
      "learning_rate": 0.0009481866749636856,
      "loss": 1.5031,
      "step": 2550
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.45849335193634033,
      "learning_rate": 0.0009469704223047085,
      "loss": 1.5578,
      "step": 2575
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.8312591314315796,
      "learning_rate": 0.0009457408585082355,
      "loss": 1.5293,
      "step": 2600
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.4841647744178772,
      "learning_rate": 0.0009444980201916622,
      "loss": 1.5015,
      "step": 2625
    },
    {
      "epoch": 0.36,
      "grad_norm": 4.7006635665893555,
      "learning_rate": 0.00094324194436771,
      "loss": 1.5106,
      "step": 2650
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.4541172683238983,
      "learning_rate": 0.000941972668443324,
      "loss": 1.494,
      "step": 2675
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.9427776336669922,
      "learning_rate": 0.0009406902302185587,
      "loss": 1.4695,
      "step": 2700
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.4607069790363312,
      "learning_rate": 0.0009393946678854525,
      "loss": 1.5166,
      "step": 2725
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.9408721327781677,
      "learning_rate": 0.0009380860200268904,
      "loss": 1.4594,
      "step": 2750
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.5118038654327393,
      "learning_rate": 0.0009367643256154544,
      "loss": 1.4937,
      "step": 2775
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.9331363439559937,
      "learning_rate": 0.0009354296240122639,
      "loss": 1.4916,
      "step": 2800
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.4732092022895813,
      "learning_rate": 0.0009340819549658026,
      "loss": 1.5251,
      "step": 2825
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.0767046213150024,
      "learning_rate": 0.000932721358610735,
      "loss": 1.5122,
      "step": 2850
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.48859652876853943,
      "learning_rate": 0.0009313478754667114,
      "loss": 1.5148,
      "step": 2875
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.047812581062317,
      "learning_rate": 0.0009299615464371607,
      "loss": 1.4881,
      "step": 2900
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5361508727073669,
      "learning_rate": 0.000928562412808073,
      "loss": 1.4845,
      "step": 2925
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.111563801765442,
      "learning_rate": 0.0009271505162467692,
      "loss": 1.5177,
      "step": 2950
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.472008615732193,
      "learning_rate": 0.0009257258988006611,
      "loss": 1.5262,
      "step": 2975
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.9545850157737732,
      "learning_rate": 0.0009242886028959978,
      "loss": 1.4999,
      "step": 3000
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.4810554087162018,
      "learning_rate": 0.0009228386713366042,
      "loss": 1.5246,
      "step": 3025
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.133015751838684,
      "learning_rate": 0.0009213761473026038,
      "loss": 1.4825,
      "step": 3050
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.43463850021362305,
      "learning_rate": 0.0009199010743491351,
      "loss": 1.5248,
      "step": 3075
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.9343062043190002,
      "learning_rate": 0.0009184134964050534,
      "loss": 1.4996,
      "step": 3100
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.5251020789146423,
      "learning_rate": 0.0009169134577716221,
      "loss": 1.5095,
      "step": 3125
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.9698643088340759,
      "learning_rate": 0.0009154010031211943,
      "loss": 1.5061,
      "step": 3150
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.41427773237228394,
      "learning_rate": 0.0009138761774958821,
      "loss": 1.5034,
      "step": 3175
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.1408066749572754,
      "learning_rate": 0.0009123390263062149,
      "loss": 1.4707,
      "step": 3200
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5149813294410706,
      "learning_rate": 0.0009107895953297874,
      "loss": 1.5097,
      "step": 3225
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.000160813331604,
      "learning_rate": 0.0009092279307098962,
      "loss": 1.5068,
      "step": 3250
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.4764212667942047,
      "learning_rate": 0.0009076540789541656,
      "loss": 1.4443,
      "step": 3275
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.9603632688522339,
      "learning_rate": 0.0009060680869331626,
      "loss": 1.5254,
      "step": 3300
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5166996121406555,
      "learning_rate": 0.0009044700018790011,
      "loss": 1.5276,
      "step": 3325
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.0347185134887695,
      "learning_rate": 0.0009028598713839348,
      "loss": 1.5211,
      "step": 3350
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.46762987971305847,
      "learning_rate": 0.0009012377433989414,
      "loss": 1.4955,
      "step": 3375
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.295729160308838,
      "learning_rate": 0.0008996036662322917,
      "loss": 1.5097,
      "step": 3400
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.4712415337562561,
      "learning_rate": 0.0008979576885481145,
      "loss": 1.5575,
      "step": 3425
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.9316529035568237,
      "learning_rate": 0.0008962998593649443,
      "loss": 1.4902,
      "step": 3450
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5217359066009521,
      "learning_rate": 0.0008946302280542633,
      "loss": 1.5121,
      "step": 3475
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.9406155347824097,
      "learning_rate": 0.0008929488443390305,
      "loss": 1.5074,
      "step": 3500
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.4827462434768677,
      "learning_rate": 0.0008912557582922008,
      "loss": 1.5057,
      "step": 3525
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.8077508211135864,
      "learning_rate": 0.000889551020335234,
      "loss": 1.5,
      "step": 3550
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.47254255414009094,
      "learning_rate": 0.000887834681236593,
      "loss": 1.5067,
      "step": 3575
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.0250718593597412,
      "learning_rate": 0.000886106792110232,
      "loss": 1.4696,
      "step": 3600
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.4670018255710602,
      "learning_rate": 0.0008843674044140745,
      "loss": 1.4881,
      "step": 3625
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.9923801422119141,
      "learning_rate": 0.0008826165699484807,
      "loss": 1.5181,
      "step": 3650
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5460423231124878,
      "learning_rate": 0.0008808543408547042,
      "loss": 1.4917,
      "step": 3675
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.0561702251434326,
      "learning_rate": 0.0008790807696133403,
      "loss": 1.4936,
      "step": 3700
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5435494780540466,
      "learning_rate": 0.0008772959090427622,
      "loss": 1.4968,
      "step": 3725
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.9613692164421082,
      "learning_rate": 0.0008754998122975488,
      "loss": 1.4835,
      "step": 3750
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.45439162850379944,
      "learning_rate": 0.000873692532866901,
      "loss": 1.5003,
      "step": 3775
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.9778909683227539,
      "learning_rate": 0.0008718741245730488,
      "loss": 1.5414,
      "step": 3800
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5191068053245544,
      "learning_rate": 0.0008700446415696492,
      "loss": 1.5069,
      "step": 3825
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.8682641386985779,
      "learning_rate": 0.0008682041383401729,
      "loss": 1.5133,
      "step": 3850
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.4929358661174774,
      "learning_rate": 0.0008663526696962809,
      "loss": 1.5093,
      "step": 3875
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.1067053079605103,
      "learning_rate": 0.0008644902907761941,
      "loss": 1.5021,
      "step": 3900
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.44951730966567993,
      "learning_rate": 0.0008626170570430498,
      "loss": 1.4996,
      "step": 3925
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.9622079133987427,
      "learning_rate": 0.0008607330242832499,
      "loss": 1.5262,
      "step": 3950
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5194354057312012,
      "learning_rate": 0.0008588382486048007,
      "loss": 1.5013,
      "step": 3975
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.191197156906128,
      "learning_rate": 0.0008569327864356409,
      "loss": 1.5254,
      "step": 4000
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.4948700964450836,
      "learning_rate": 0.0008550166945219611,
      "loss": 1.5016,
      "step": 4025
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.9857603907585144,
      "learning_rate": 0.0008530900299265148,
      "loss": 1.4523,
      "step": 4050
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.557930588722229,
      "learning_rate": 0.0008511528500269181,
      "loss": 1.5418,
      "step": 4075
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.1943731307983398,
      "learning_rate": 0.0008492052125139414,
      "loss": 1.4947,
      "step": 4100
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6223617196083069,
      "learning_rate": 0.0008472471753897912,
      "loss": 1.4765,
      "step": 4125
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.0469859838485718,
      "learning_rate": 0.0008452787969663827,
      "loss": 1.501,
      "step": 4150
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.47983720898628235,
      "learning_rate": 0.0008433001358636034,
      "loss": 1.5035,
      "step": 4175
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.145473599433899,
      "learning_rate": 0.0008413112510075671,
      "loss": 1.541,
      "step": 4200
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5172563791275024,
      "learning_rate": 0.0008393122016288593,
      "loss": 1.5153,
      "step": 4225
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.295767903327942,
      "learning_rate": 0.0008373030472607728,
      "loss": 1.4824,
      "step": 4250
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5272517204284668,
      "learning_rate": 0.0008352838477375357,
      "loss": 1.4754,
      "step": 4275
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.8700576424598694,
      "learning_rate": 0.0008332546631925284,
      "loss": 1.4788,
      "step": 4300
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.46357354521751404,
      "learning_rate": 0.0008312155540564933,
      "loss": 1.4992,
      "step": 4325
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.9196488857269287,
      "learning_rate": 0.0008291665810557352,
      "loss": 1.4886,
      "step": 4350
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.47137343883514404,
      "learning_rate": 0.0008271078052103127,
      "loss": 1.492,
      "step": 4375
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.8447813987731934,
      "learning_rate": 0.0008250392878322206,
      "loss": 1.5062,
      "step": 4400
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.4742294251918793,
      "learning_rate": 0.0008229610905235652,
      "loss": 1.477,
      "step": 4425
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.8672488331794739,
      "learning_rate": 0.000820873275174728,
      "loss": 1.4536,
      "step": 4450
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5123589038848877,
      "learning_rate": 0.000818775903962524,
      "loss": 1.5066,
      "step": 4475
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.7877087593078613,
      "learning_rate": 0.0008166690393483491,
      "loss": 1.4794,
      "step": 4500
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5646103024482727,
      "learning_rate": 0.0008145527440763205,
      "loss": 1.4664,
      "step": 4525
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.8581407070159912,
      "learning_rate": 0.0008124270811714083,
      "loss": 1.4844,
      "step": 4550
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5536981225013733,
      "learning_rate": 0.0008102921139375574,
      "loss": 1.4723,
      "step": 4575
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.8747391700744629,
      "learning_rate": 0.0008081479059558039,
      "loss": 1.4884,
      "step": 4600
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5388346910476685,
      "learning_rate": 0.0008059945210823802,
      "loss": 1.4877,
      "step": 4625
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.8874062299728394,
      "learning_rate": 0.0008038320234468144,
      "loss": 1.4646,
      "step": 4650
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5100805163383484,
      "learning_rate": 0.0008016604774500195,
      "loss": 1.5048,
      "step": 4675
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.0664467811584473,
      "learning_rate": 0.000799479947762376,
      "loss": 1.4598,
      "step": 4700
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.48184511065483093,
      "learning_rate": 0.0007972904993218062,
      "loss": 1.4567,
      "step": 4725
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.893410325050354,
      "learning_rate": 0.00079509219733184,
      "loss": 1.4863,
      "step": 4750
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5157738924026489,
      "learning_rate": 0.0007928851072596726,
      "loss": 1.496,
      "step": 4775
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.5896642208099365,
      "learning_rate": 0.000790669294834216,
      "loss": 1.4676,
      "step": 4800
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5013481378555298,
      "learning_rate": 0.0007884448260441405,
      "loss": 1.5116,
      "step": 4825
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.041477918624878,
      "learning_rate": 0.0007862117671359097,
      "loss": 1.4955,
      "step": 4850
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.4567871689796448,
      "learning_rate": 0.0007839701846118086,
      "loss": 1.4918,
      "step": 4875
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.0028471946716309,
      "learning_rate": 0.0007817201452279611,
      "loss": 1.4911,
      "step": 4900
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.4765322506427765,
      "learning_rate": 0.0007794617159923443,
      "loss": 1.5148,
      "step": 4925
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.9694713950157166,
      "learning_rate": 0.0007771949641627911,
      "loss": 1.4544,
      "step": 4950
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.49554872512817383,
      "learning_rate": 0.0007749199572449882,
      "loss": 1.5042,
      "step": 4975
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.0656194686889648,
      "learning_rate": 0.0007726367629904655,
      "loss": 1.5103,
      "step": 5000
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.47956719994544983,
      "learning_rate": 0.000770345449394578,
      "loss": 1.4721,
      "step": 5025
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.0869343280792236,
      "learning_rate": 0.0007680460846944819,
      "loss": 1.4965,
      "step": 5050
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.5413355231285095,
      "learning_rate": 0.0007657387373671007,
      "loss": 1.4796,
      "step": 5075
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.9620445966720581,
      "learning_rate": 0.0007634234761270882,
      "loss": 1.4801,
      "step": 5100
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.4855995178222656,
      "learning_rate": 0.0007611003699247796,
      "loss": 1.4868,
      "step": 5125
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.3201236724853516,
      "learning_rate": 0.0007587694879441401,
      "loss": 1.4773,
      "step": 5150
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.4878068268299103,
      "learning_rate": 0.0007564308996007039,
      "loss": 1.4935,
      "step": 5175
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.9678477048873901,
      "learning_rate": 0.0007540846745395064,
      "loss": 1.4317,
      "step": 5200
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.5102419853210449,
      "learning_rate": 0.0007517308826330109,
      "loss": 1.4951,
      "step": 5225
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.9205783009529114,
      "learning_rate": 0.0007493695939790273,
      "loss": 1.4822,
      "step": 5250
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.5553131103515625,
      "learning_rate": 0.0007470008788986246,
      "loss": 1.5397,
      "step": 5275
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.9931799173355103,
      "learning_rate": 0.0007446248079340368,
      "loss": 1.4578,
      "step": 5300
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.49964553117752075,
      "learning_rate": 0.0007422414518465622,
      "loss": 1.4424,
      "step": 5325
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.8565728068351746,
      "learning_rate": 0.0007398508816144556,
      "loss": 1.4741,
      "step": 5350
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.4757745862007141,
      "learning_rate": 0.000737453168430815,
      "loss": 1.4911,
      "step": 5375
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.9338400363922119,
      "learning_rate": 0.0007350483837014611,
      "loss": 1.4297,
      "step": 5400
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.49604305624961853,
      "learning_rate": 0.0007326365990428111,
      "loss": 1.4862,
      "step": 5425
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.8775596618652344,
      "learning_rate": 0.0007302178862797454,
      "loss": 1.4783,
      "step": 5450
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.4981885552406311,
      "learning_rate": 0.0007277923174434693,
      "loss": 1.4656,
      "step": 5475
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.0511822700500488,
      "learning_rate": 0.0007253599647693669,
      "loss": 1.4672,
      "step": 5500
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.5829374194145203,
      "learning_rate": 0.0007229209006948509,
      "loss": 1.4494,
      "step": 5525
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.058194637298584,
      "learning_rate": 0.0007204751978572051,
      "loss": 1.4659,
      "step": 5550
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.5253037810325623,
      "learning_rate": 0.0007180229290914202,
      "loss": 1.4759,
      "step": 5575
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.9913164973258972,
      "learning_rate": 0.0007155641674280261,
      "loss": 1.4676,
      "step": 5600
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.48473915457725525,
      "learning_rate": 0.0007130989860909162,
      "loss": 1.4453,
      "step": 5625
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.070939540863037,
      "learning_rate": 0.0007106274584951669,
      "loss": 1.5059,
      "step": 5650
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.5278321504592896,
      "learning_rate": 0.0007081496582448515,
      "loss": 1.5074,
      "step": 5675
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.9991098642349243,
      "learning_rate": 0.0007056656591308475,
      "loss": 1.4618,
      "step": 5700
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.4920244812965393,
      "learning_rate": 0.0007031755351286403,
      "loss": 1.4459,
      "step": 5725
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.1303176879882812,
      "learning_rate": 0.0007006793603961186,
      "loss": 1.4421,
      "step": 5750
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.4654746651649475,
      "learning_rate": 0.0006981772092713671,
      "loss": 1.4677,
      "step": 5775
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.0745457410812378,
      "learning_rate": 0.0006956691562704522,
      "loss": 1.4625,
      "step": 5800
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.508783221244812,
      "learning_rate": 0.0006931552760852029,
      "loss": 1.4625,
      "step": 5825
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.9093919992446899,
      "learning_rate": 0.0006906356435809863,
      "loss": 1.4279,
      "step": 5850
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.4525470733642578,
      "learning_rate": 0.0006881103337944784,
      "loss": 1.4458,
      "step": 5875
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.9172658920288086,
      "learning_rate": 0.0006855794219314291,
      "loss": 1.4312,
      "step": 5900
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.49701443314552307,
      "learning_rate": 0.0006830429833644225,
      "loss": 1.4319,
      "step": 5925
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.3877553939819336,
      "learning_rate": 0.0006805010936306325,
      "loss": 1.4147,
      "step": 5950
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.4754308760166168,
      "learning_rate": 0.0006779538284295731,
      "loss": 1.4609,
      "step": 5975
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.0670905113220215,
      "learning_rate": 0.0006754012636208442,
      "loss": 1.4582,
      "step": 6000
    }
  ],
  "logging_steps": 25,
  "max_steps": 14838,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 1000,
  "total_flos": 1.222655342657495e+18,
  "train_batch_size": 5,
  "trial_name": null,
  "trial_params": null
}
