{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.5391562205148942,
  "eval_steps": 500,
  "global_step": 4000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 0.07861328125,
      "learning_rate": 5.6053811659192826e-05,
      "loss": 1.8408,
      "step": 25
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6484375,
      "learning_rate": 0.00011210762331838565,
      "loss": 1.8565,
      "step": 50
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.13671875,
      "learning_rate": 0.00016816143497757848,
      "loss": 1.6559,
      "step": 75
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.35546875,
      "learning_rate": 0.0002242152466367713,
      "loss": 1.567,
      "step": 100
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.10595703125,
      "learning_rate": 0.0002802690582959641,
      "loss": 1.5625,
      "step": 125
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.291015625,
      "learning_rate": 0.00033632286995515697,
      "loss": 1.532,
      "step": 150
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.1005859375,
      "learning_rate": 0.0003923766816143498,
      "loss": 1.5531,
      "step": 175
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.255859375,
      "learning_rate": 0.0004484304932735426,
      "loss": 1.4931,
      "step": 200
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.10791015625,
      "learning_rate": 0.0005044843049327355,
      "loss": 1.5265,
      "step": 225
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.171875,
      "learning_rate": 0.0005605381165919282,
      "loss": 1.4902,
      "step": 250
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.095703125,
      "learning_rate": 0.0006165919282511211,
      "loss": 1.4749,
      "step": 275
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.2216796875,
      "learning_rate": 0.0006726457399103139,
      "loss": 1.4972,
      "step": 300
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.09375,
      "learning_rate": 0.0007286995515695067,
      "loss": 1.4882,
      "step": 325
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.1708984375,
      "learning_rate": 0.0007847533632286996,
      "loss": 1.4832,
      "step": 350
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.10302734375,
      "learning_rate": 0.0008408071748878924,
      "loss": 1.4537,
      "step": 375
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.244140625,
      "learning_rate": 0.0008968609865470852,
      "loss": 1.4699,
      "step": 400
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.10791015625,
      "learning_rate": 0.000952914798206278,
      "loss": 1.5183,
      "step": 425
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.2490234375,
      "learning_rate": 0.0009999998094024085,
      "loss": 1.4958,
      "step": 450
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.09326171875,
      "learning_rate": 0.000999989981746913,
      "loss": 1.474,
      "step": 475
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.1728515625,
      "learning_rate": 0.0009999652639889381,
      "loss": 1.4584,
      "step": 500
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.10302734375,
      "learning_rate": 0.000999925656864598,
      "loss": 1.5224,
      "step": 525
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.2197265625,
      "learning_rate": 0.0009998711615534243,
      "loss": 1.4699,
      "step": 550
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.11767578125,
      "learning_rate": 0.0009998017796783315,
      "loss": 1.4903,
      "step": 575
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.1875,
      "learning_rate": 0.0009997175133055675,
      "loss": 1.4809,
      "step": 600
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.103515625,
      "learning_rate": 0.0009996183649446523,
      "loss": 1.4473,
      "step": 625
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.1611328125,
      "learning_rate": 0.0009995043375483033,
      "loss": 1.4503,
      "step": 650
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.10205078125,
      "learning_rate": 0.0009993754345123482,
      "loss": 1.4389,
      "step": 675
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.255859375,
      "learning_rate": 0.0009992316596756227,
      "loss": 1.4486,
      "step": 700
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.10986328125,
      "learning_rate": 0.0009990730173198563,
      "loss": 1.4637,
      "step": 725
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.3515625,
      "learning_rate": 0.000998899512169546,
      "loss": 1.4288,
      "step": 750
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.107421875,
      "learning_rate": 0.0009987111493918142,
      "loss": 1.4871,
      "step": 775
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.2412109375,
      "learning_rate": 0.000998507934596255,
      "loss": 1.4954,
      "step": 800
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.10595703125,
      "learning_rate": 0.0009982898738347685,
      "loss": 1.4554,
      "step": 825
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.255859375,
      "learning_rate": 0.0009980569736013788,
      "loss": 1.4413,
      "step": 850
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.1240234375,
      "learning_rate": 0.0009978092408320413,
      "loss": 1.476,
      "step": 875
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.333984375,
      "learning_rate": 0.0009975466829044365,
      "loss": 1.429,
      "step": 900
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.1162109375,
      "learning_rate": 0.0009972693076377502,
      "loss": 1.4695,
      "step": 925
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.232421875,
      "learning_rate": 0.0009969771232924403,
      "loss": 1.4569,
      "step": 950
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.11767578125,
      "learning_rate": 0.0009966701385699904,
      "loss": 1.5006,
      "step": 975
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.205078125,
      "learning_rate": 0.000996348362612652,
      "loss": 1.4314,
      "step": 1000
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.1171875,
      "learning_rate": 0.000996011805003171,
      "loss": 1.4784,
      "step": 1025
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.240234375,
      "learning_rate": 0.0009956604757645027,
      "loss": 1.4604,
      "step": 1050
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.11865234375,
      "learning_rate": 0.0009952943853595135,
      "loss": 1.4451,
      "step": 1075
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.298828125,
      "learning_rate": 0.0009949135446906691,
      "loss": 1.4689,
      "step": 1100
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.1162109375,
      "learning_rate": 0.0009945179650997103,
      "loss": 1.4911,
      "step": 1125
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.2578125,
      "learning_rate": 0.000994107658367314,
      "loss": 1.45,
      "step": 1150
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.11669921875,
      "learning_rate": 0.0009936826367127438,
      "loss": 1.4872,
      "step": 1175
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.259765625,
      "learning_rate": 0.0009932429127934852,
      "loss": 1.4552,
      "step": 1200
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.12060546875,
      "learning_rate": 0.0009927884997048692,
      "loss": 1.4608,
      "step": 1225
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.236328125,
      "learning_rate": 0.0009923194109796815,
      "loss": 1.445,
      "step": 1250
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.13671875,
      "learning_rate": 0.0009918356605877609,
      "loss": 1.4203,
      "step": 1275
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.2578125,
      "learning_rate": 0.0009913372629355814,
      "loss": 1.4067,
      "step": 1300
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.1318359375,
      "learning_rate": 0.0009908242328658249,
      "loss": 1.4698,
      "step": 1325
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.34765625,
      "learning_rate": 0.0009902965856569382,
      "loss": 1.4484,
      "step": 1350
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.12158203125,
      "learning_rate": 0.000989754337022678,
      "loss": 1.4786,
      "step": 1375
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.263671875,
      "learning_rate": 0.0009891975031116433,
      "loss": 1.4421,
      "step": 1400
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.1416015625,
      "learning_rate": 0.0009886261005067948,
      "loss": 1.4636,
      "step": 1425
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.265625,
      "learning_rate": 0.0009880401462249596,
      "loss": 1.4468,
      "step": 1450
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.11962890625,
      "learning_rate": 0.000987439657716326,
      "loss": 1.4349,
      "step": 1475
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.24609375,
      "learning_rate": 0.0009868246528639236,
      "loss": 1.4287,
      "step": 1500
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.12255859375,
      "learning_rate": 0.0009861951499830894,
      "loss": 1.4418,
      "step": 1525
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.271484375,
      "learning_rate": 0.0009855511678209243,
      "loss": 1.4456,
      "step": 1550
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.12890625,
      "learning_rate": 0.0009848927255557331,
      "loss": 1.4495,
      "step": 1575
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.26171875,
      "learning_rate": 0.0009842198427964545,
      "loss": 1.4078,
      "step": 1600
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.130859375,
      "learning_rate": 0.0009835325395820761,
      "loss": 1.4725,
      "step": 1625
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.291015625,
      "learning_rate": 0.0009828308363810392,
      "loss": 1.4521,
      "step": 1650
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.1318359375,
      "learning_rate": 0.0009821147540906273,
      "loss": 1.4815,
      "step": 1675
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.267578125,
      "learning_rate": 0.0009813843140363447,
      "loss": 1.4333,
      "step": 1700
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.1298828125,
      "learning_rate": 0.0009806395379712825,
      "loss": 1.4429,
      "step": 1725
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.3125,
      "learning_rate": 0.0009798804480754687,
      "loss": 1.3671,
      "step": 1750
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.1328125,
      "learning_rate": 0.0009791070669552086,
      "loss": 1.4402,
      "step": 1775
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.275390625,
      "learning_rate": 0.0009783194176424125,
      "loss": 1.4216,
      "step": 1800
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.126953125,
      "learning_rate": 0.0009775175235939078,
      "loss": 1.4101,
      "step": 1825
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.2392578125,
      "learning_rate": 0.0009767014086907427,
      "loss": 1.437,
      "step": 1850
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.13671875,
      "learning_rate": 0.0009758710972374729,
      "loss": 1.4284,
      "step": 1875
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.2578125,
      "learning_rate": 0.0009750266139614391,
      "loss": 1.4088,
      "step": 1900
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.126953125,
      "learning_rate": 0.0009741679840120303,
      "loss": 1.4173,
      "step": 1925
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.26171875,
      "learning_rate": 0.000973295232959935,
      "loss": 1.3939,
      "step": 1950
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.1279296875,
      "learning_rate": 0.0009724083867963787,
      "loss": 1.4487,
      "step": 1975
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.2578125,
      "learning_rate": 0.0009715074719323514,
      "loss": 1.4017,
      "step": 2000
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.1484375,
      "learning_rate": 0.00097059251519782,
      "loss": 1.4465,
      "step": 2025
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.294921875,
      "learning_rate": 0.0009696635438409294,
      "loss": 1.4202,
      "step": 2050
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.1259765625,
      "learning_rate": 0.0009687205855271915,
      "loss": 1.4134,
      "step": 2075
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.3515625,
      "learning_rate": 0.0009677636683386606,
      "loss": 1.4005,
      "step": 2100
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.1328125,
      "learning_rate": 0.0009667928207730978,
      "loss": 1.3956,
      "step": 2125
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.2734375,
      "learning_rate": 0.0009658080717431222,
      "loss": 1.4406,
      "step": 2150
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.1435546875,
      "learning_rate": 0.0009648094505753486,
      "loss": 1.4702,
      "step": 2175
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.244140625,
      "learning_rate": 0.0009637969870095167,
      "loss": 1.4109,
      "step": 2200
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.1416015625,
      "learning_rate": 0.0009627707111976027,
      "loss": 1.4263,
      "step": 2225
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.310546875,
      "learning_rate": 0.0009617306537029233,
      "loss": 1.4149,
      "step": 2250
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.1328125,
      "learning_rate": 0.0009606768454992243,
      "loss": 1.3972,
      "step": 2275
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.283203125,
      "learning_rate": 0.0009596093179697588,
      "loss": 1.4051,
      "step": 2300
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.146484375,
      "learning_rate": 0.0009585281029063522,
      "loss": 1.4355,
      "step": 2325
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.265625,
      "learning_rate": 0.0009574332325084562,
      "loss": 1.3743,
      "step": 2350
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.1396484375,
      "learning_rate": 0.000956324739382189,
      "loss": 1.4317,
      "step": 2375
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.2734375,
      "learning_rate": 0.0009552026565393644,
      "loss": 1.3783,
      "step": 2400
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.1455078125,
      "learning_rate": 0.0009540670173965089,
      "loss": 1.4435,
      "step": 2425
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.259765625,
      "learning_rate": 0.0009529178557738667,
      "loss": 1.3861,
      "step": 2450
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.12451171875,
      "learning_rate": 0.0009517552058943921,
      "loss": 1.383,
      "step": 2475
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.294921875,
      "learning_rate": 0.0009505791023827308,
      "loss": 1.4274,
      "step": 2500
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.1416015625,
      "learning_rate": 0.0009493895802641879,
      "loss": 1.434,
      "step": 2525
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.32421875,
      "learning_rate": 0.0009481866749636856,
      "loss": 1.4085,
      "step": 2550
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.142578125,
      "learning_rate": 0.0009469704223047085,
      "loss": 1.472,
      "step": 2575
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.2734375,
      "learning_rate": 0.0009457408585082355,
      "loss": 1.4339,
      "step": 2600
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.1435546875,
      "learning_rate": 0.0009444980201916622,
      "loss": 1.4058,
      "step": 2625
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.302734375,
      "learning_rate": 0.00094324194436771,
      "loss": 1.4097,
      "step": 2650
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.1494140625,
      "learning_rate": 0.000941972668443324,
      "loss": 1.4076,
      "step": 2675
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.2421875,
      "learning_rate": 0.0009406902302185587,
      "loss": 1.3757,
      "step": 2700
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.1357421875,
      "learning_rate": 0.0009393946678854525,
      "loss": 1.43,
      "step": 2725
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.26171875,
      "learning_rate": 0.0009380860200268904,
      "loss": 1.3563,
      "step": 2750
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.1328125,
      "learning_rate": 0.0009367643256154544,
      "loss": 1.402,
      "step": 2775
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.267578125,
      "learning_rate": 0.0009354296240122639,
      "loss": 1.3915,
      "step": 2800
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.1611328125,
      "learning_rate": 0.0009340819549658026,
      "loss": 1.4386,
      "step": 2825
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.3046875,
      "learning_rate": 0.000932721358610735,
      "loss": 1.4153,
      "step": 2850
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.162109375,
      "learning_rate": 0.0009313478754667114,
      "loss": 1.4246,
      "step": 2875
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.3203125,
      "learning_rate": 0.0009299615464371607,
      "loss": 1.4,
      "step": 2900
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.1533203125,
      "learning_rate": 0.000928562412808073,
      "loss": 1.3957,
      "step": 2925
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.3671875,
      "learning_rate": 0.0009271505162467692,
      "loss": 1.4145,
      "step": 2950
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.1513671875,
      "learning_rate": 0.0009257258988006611,
      "loss": 1.437,
      "step": 2975
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.30078125,
      "learning_rate": 0.0009242886028959978,
      "loss": 1.403,
      "step": 3000
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.12890625,
      "learning_rate": 0.0009228386713366042,
      "loss": 1.4303,
      "step": 3025
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.294921875,
      "learning_rate": 0.0009213761473026038,
      "loss": 1.3806,
      "step": 3050
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.1650390625,
      "learning_rate": 0.0009199010743491351,
      "loss": 1.4426,
      "step": 3075
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.271484375,
      "learning_rate": 0.0009184134964050534,
      "loss": 1.393,
      "step": 3100
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.1669921875,
      "learning_rate": 0.0009169134577716221,
      "loss": 1.4123,
      "step": 3125
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.263671875,
      "learning_rate": 0.0009154010031211943,
      "loss": 1.409,
      "step": 3150
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.14453125,
      "learning_rate": 0.0009138761774958821,
      "loss": 1.4092,
      "step": 3175
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.40625,
      "learning_rate": 0.0009123390263062149,
      "loss": 1.3745,
      "step": 3200
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.1484375,
      "learning_rate": 0.0009107895953297874,
      "loss": 1.4192,
      "step": 3225
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.28125,
      "learning_rate": 0.0009092279307098962,
      "loss": 1.4084,
      "step": 3250
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.146484375,
      "learning_rate": 0.0009076540789541656,
      "loss": 1.3562,
      "step": 3275
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.2373046875,
      "learning_rate": 0.0009060680869331626,
      "loss": 1.4148,
      "step": 3300
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.1484375,
      "learning_rate": 0.0009044700018790011,
      "loss": 1.4317,
      "step": 3325
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.32421875,
      "learning_rate": 0.0009028598713839348,
      "loss": 1.4153,
      "step": 3350
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.1552734375,
      "learning_rate": 0.0009012377433989414,
      "loss": 1.3967,
      "step": 3375
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.32421875,
      "learning_rate": 0.0008996036662322917,
      "loss": 1.4076,
      "step": 3400
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.1533203125,
      "learning_rate": 0.0008979576885481145,
      "loss": 1.4582,
      "step": 3425
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.28515625,
      "learning_rate": 0.0008962998593649443,
      "loss": 1.3932,
      "step": 3450
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.1669921875,
      "learning_rate": 0.0008946302280542633,
      "loss": 1.4182,
      "step": 3475
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.271484375,
      "learning_rate": 0.0008929488443390305,
      "loss": 1.4115,
      "step": 3500
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.154296875,
      "learning_rate": 0.0008912557582922008,
      "loss": 1.4097,
      "step": 3525
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.271484375,
      "learning_rate": 0.000889551020335234,
      "loss": 1.3996,
      "step": 3550
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.138671875,
      "learning_rate": 0.000887834681236593,
      "loss": 1.4098,
      "step": 3575
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.30859375,
      "learning_rate": 0.000886106792110232,
      "loss": 1.3723,
      "step": 3600
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.16015625,
      "learning_rate": 0.0008843674044140745,
      "loss": 1.3968,
      "step": 3625
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.279296875,
      "learning_rate": 0.0008826165699484807,
      "loss": 1.4152,
      "step": 3650
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.1572265625,
      "learning_rate": 0.0008808543408547042,
      "loss": 1.4013,
      "step": 3675
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.318359375,
      "learning_rate": 0.0008790807696133403,
      "loss": 1.3869,
      "step": 3700
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.140625,
      "learning_rate": 0.0008772959090427622,
      "loss": 1.3936,
      "step": 3725
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.2578125,
      "learning_rate": 0.0008754998122975488,
      "loss": 1.3832,
      "step": 3750
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.197265625,
      "learning_rate": 0.000873692532866901,
      "loss": 1.4024,
      "step": 3775
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.326171875,
      "learning_rate": 0.0008718741245730488,
      "loss": 1.4305,
      "step": 3800
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.154296875,
      "learning_rate": 0.0008700446415696492,
      "loss": 1.4105,
      "step": 3825
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.265625,
      "learning_rate": 0.0008682041383401729,
      "loss": 1.3994,
      "step": 3850
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.1796875,
      "learning_rate": 0.0008663526696962809,
      "loss": 1.4101,
      "step": 3875
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.283203125,
      "learning_rate": 0.0008644902907761941,
      "loss": 1.3893,
      "step": 3900
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.1455078125,
      "learning_rate": 0.0008626170570430498,
      "loss": 1.4036,
      "step": 3925
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.3125,
      "learning_rate": 0.0008607330242832499,
      "loss": 1.4211,
      "step": 3950
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.16015625,
      "learning_rate": 0.0008588382486048007,
      "loss": 1.4072,
      "step": 3975
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.337890625,
      "learning_rate": 0.0008569327864356409,
      "loss": 1.4237,
      "step": 4000
    }
  ],
  "logging_steps": 25,
  "max_steps": 14838,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 1000,
  "total_flos": 7.606645998001766e+17,
  "train_batch_size": 5,
  "trial_name": null,
  "trial_params": null
}
